\chapter{Basics} 
\label{ch:Basics}

To understand the following Iterative Learning Control (ILC) algorithms, a few basic definitions are presented in this chapter. 
Again, the considered system is given via 
\begin{align}
\label{eq:Basics:GP}
\begin{split}
&\begin{array}{c c c c c}
x(t+1) &= &A x(t)& + &B u(t)  \\
y ( t) &= &C x(t)&  + &D u(t),\\ 
x(0)& = &x_0. & &
\end{array}\\
\end{split}
\end{align}
 Here $A \in \mathbb{R}^{n\times n}$, $B \in \mathbb{R}^{n \times l}$, $C \in \R^{m \times n}$, and $D \in \R^{m\times l}$ are real matrices, $r(t) \in \R^{m}$ is a reference signal at time $t$. For notation simplification, a short description for the discrete-time control system \eqref{eq:Basics:GP} is denoted with $(A, B,C,D)$. 

In the basic tracking issue, there is sought an input $u(\cdot)$, which renders the output $y(\cdot)$ of a system \eqref{eq:Basics:GP} to lie close to the tracking signal $r(\cdot)$. That means, that the error $e(\cdot):= y(\cdot) - r(\cdot)$ must stay small in some norm  $||\cdot||$, e.g. the $L_2$-norm. To find it usually a stabilizing controller is designed -- such that the system state $x(\cdot)$ goes not to infinity over time $t$. 
To design it, the stability needs a clear definition. 

The stability definition is usually given asymptotically, i.e. $t \to \infty$. Though in this thesis there are the systems over a finite time horizon of interest, it still makes sense to take this ''classical'' definition of stability, as it is discussed later.  

\begin{defi}
	A discrete time dynamical system
	\begin{align}
	\label{eq:x=Ax}
	x(t+1) = A x(t)
	\end{align}
	for $t \geq 0$ 
	is said to be asymptotically stable, if for all initial conditions $x(0) \in \R^n$
	\begin{align}
	\lim_{t \to \infty} x(t) = 0
	\end{align}	
    is satisfied. 
	It is said to be stable, if 
	\begin{align}
	\limsup_{t \to \infty} ||x(t)|| < \infty
	\end{align}
	for all	 initial conditions $x(0) \in \R^n$.
	The matrix $A$ is (asymptotically) stable, if the dynamical system \eqref{eq:x=Ax} is (asymptotically) stable.
\end{defi}



\begin{defi}
A discrete time system $(A, B, C, D)$ or the pair $(A, B)$ is (asymptotically) stabilizable, if there exists a matrix $F$, such that $A - BF$ is (asymptotically) stable.
The system or the pair $(A,C)$ is detectable, if $(A^T, C^T)$ is assymptotically stabilizable. 
\end{defi}

Another useful definition is the definiteness of a matrix. This is given as follows. 
\begin{defi}
	A symmetric matrix $A \in \R^{n \times n}$ is negative definite if $x^T A x < 0$ for all $x \in \R^n$, $x \neq 0$. It is negative semi-definite, if $x^T A x \leq 0$ for all $x \in \R^n$. 
	In the same way, the matrix $A$ is positive definite, if $x^T A x >0$ for all $x \in \R^n$, $x \neq 0$, and positive semi-definite, if $x^T A x \geq 0$ for all $x \in \R^n$. 
	
	The symbols $\prec, \preceq, \succ, \succeq$ for two symmetric matrices $A, B \in \R^{n \times n}$ are defined as follows:
	\begin{subequations}
		\begin{align}
		A \prec B & \text{ \; \; if } A - B \text{ is negative definite},
		\\
		A \preceq B & \text{ \; \; if } A - B \text{ is negative semi-definite},		
		\\
		A \succ B & \text{ \; \; if } A - B \text{ is positive definite},
		\\
		A \succeq B & \text{ \; \; if } A - B \text{ is positive semi-definite}.
		\end{align}
	\end{subequations}
\end{defi}

\section{Supervector description} 

The supervectors are the most useful tool in this thesis. By ''stocking'' the signals together, it surrenders a compact system representation in linear form.

\begin{defi}
	Let $\{s(0), s(1), s(2), \dots s(N)\} \subset \R^{d}$ be a finite sequence. Then the supervector corresponding to this sequence is denoted by $s$ and is defined as 
	\begin{align}
	s: = \begin{pmatrix}
	s(0) \\ s(1) \\ s(2) \\ \vdots \\ s(N)
	\end{pmatrix}.
	\end{align}
\end{defi}

In this way are defined the supervectors $u \in \R^{l(N+1)} $ and $e$, $y$, $r \in \R^{m(N+1)}$.  
Then for system \eqref{eq:Basics:GP} the relation between $u$, $y$, and the error $e$ can be written as
\begin{align}
\label{eq:Gu + d}
y &= Gu + d, \\
e &= r - y.
\end{align}
The \textit{supermatrix} $G$ represents the state-space model and is given via  
\begin{align}
\label{eq:Gmatrix}
\begin{split}
G &= G(A,B,C,D) = \\
&=  \begin{pmatrix}
D & 0 & \cdots & 0 & 0 & 0 \\
CB & D & \cdots & 0 & 0 & 0\\
CAB & CB & \cdots & 0 & 0 & 0\\
\vdots & \vdots & \ddots & \vdots  & \vdots & \vdots \\
CA^{N-2} B & CA^{N-3} B &\dots &CB & D& 0\\
CA^{N-1} B & CA^{N-2} B &\dots &CAB & CB& D\\
\end{pmatrix} \in \R^{m(N+1)\times l(N+1)}.
\end{split}
\end{align}
The vector $d$ depends on the initial condition $x_0$:
\begin{align}
d = d(C,A,x_0) = \begin{pmatrix}
C x_0 \\ CA x_0 \\ CA^2 x_0 \\ \vdots \\ CA^Nx_0
\end{pmatrix} \in \R^{m(N+1)}.
\end{align}

The stability requirement for $A$ is highlighted here. As for the system \eqref{eq:x=Ax} holds
\begin{align}
x(t) = A^{t-1}x(0) \text{ for } t\geq 1, 
\end{align}
the matrix $A^t$ gets very large terms for the growing time $t$. 
In opposite, for a stable matrix $A$, $A^t$ gets small terms for $t \gg 1$\footnote{The symbol $\gg$ means much greater}. Intuitive, those terms can be neglected for all $p > p^\star$ for some $1<p^\star<N$. This allows to reduce the amount of computer memory needed, if use the sparse matrices. In Chapter \ref{ch:Allpication} an estimation based on neglecting of small terms is derived. 


\section{Separation Principle}
\label{ch:stabilizingController}

There are several ways to construct a stabilizing controller for a system $(A, B, C, D)$. For example the $\c H_\infty$ design \cite{discrHinf}, pole placement \cite{LKT} or the separation principle. The latest is presented here. Though it might render worse performance than the more advanced techniques, it offers a simple implementation. The tracking accuracy of the initial stabilizing controller (that is, implemented before using the ILC algorithms), is here not a deciding factor. The tracking accuracy will be improved later by using the ILC techniques. 

First consider the case $y(\cdot) = x(\cdot)$.
Then the system \eqref{eq:Basics:GP} becomes stable, if $u(t) = -Fx(t)$, $t \geq 0$, with some matrix $F$, such that $(A - BF)$ is stable.
Clearly, if the system is (asymptotically) stabilizable, there exists such a matrix $F$. 

But what is a ''good'' choice for $F$? One option is the so-called Linear-Quadratic-Regulator (LQR), which minimizes the cost function 
\begin{align}
\label{eq:costFcn}
V(u(\cdot)) = \sum_{t = 0}^\infty \left( (x(t))^T Q (x(t)) + u(t)^T R u(t)\right),
\end{align}
overall stabilizing piecewise constant input signals $u(\cdot) \in \R^m$, and with $x(\cdot)$ satisfying \eqref{eq:Basics:GP} (for $C = I$ and $D = 0$). 
The matrices $Q \in \R^{n \times n}$ and $R \in \R^{m \times m}$ are positive definite weighing matrices, which allow to decide how ''important'' the elements of the in- and output signals are.  
By using them, one input signal can be made to impact the system more than another or drive one of the output signals faster. 
Choosing the weighting matrices always depends on the considered system and allows to affect the closed-loop behaviour.


The optimal $u(\cdot)$ for minimizing  the cost function \eqref{eq:costFcn} is given via $u(t) = F x(t)$ with
\begin{align}
\label{eq:Basics:F}
F = (R + B^T P B)^{-1}B^TPA \text{ \cite{KostovaIvanov2013}}.
\end{align}
The matrix $P$ is a unique symmetric positive definite matrix, the stabilizing solution of the discrete time algebraic Riccati equation
\begin{align}
 A^TA - A^T P B (R + B^T P B)^{-1} B^T P A + Q - P = 0 \text{ \cite{DAREandLMI}}.
\end{align}
Stabilizing solution means, that the matrix  $(A - BF)$ resulting from \eqref{eq:Basics:F} is stable, and hence this solution stabilizes the system. 


For the case $y(\cdot) \neq x(\cdot)$, an additional observer can be implemented to approximate the signal $x(\cdot)$. Then the resulting  controller is said to be based on \textit{separation principle}.
It requires the pair $(A,C)$ to be detectable, i.e. there exists a matrix $J$, for which the matrix $A - JC$ is asymptotically stable.

Set 
\begin{align}
u(\cdot)= -F \hat{x}(\cdot), \text{ with } \hat{x}(\cdot) \text{ given via the dynamical system }
\end{align}
\begin{align}
\begin{split}
\hat{x}(t+1) &= A\hat{x}(t) + B u(t) + J (y - \hat{y}(t)), \\
\hat{y}(t) & = C\hat{x}(t) + D u(t), \\
\hat{x}(0)& = x_0, \; t \geq 0. 
\end{split}
\end{align}
With this observer system, the estimation error can be calculated as \begin{align}
\tilde{x}(t+1) = x(t+1) - \hat{x}(t+1) = (A - JC) \tilde{x}(t), \, t \geq 0,
\end{align} and as $(A - JC)$ is asymptotic stable,  the error $\tilde{x}(t+1)$ asymptotically converges to zero. 

For a constant reference signal $r(t) = r_0 \in \R^m$, $t \geq 0$, choose the input signal as 
\begin{align}
u(t) = -F\hat{x}(t) + Mr_0, \; t \geq 0,
\end{align}
with some matrix $M$ of a fitting dimension. 
Then the dynamical system 
\begin{align}
\begin{split}
\begin{pmatrix}
x(t+1) \\ \t x(t+1)
\end{pmatrix} = 
\begin{pmatrix}
A - BF & BF \\ 0 & A-J
\end{pmatrix}
\begin{pmatrix}
x(t) \\ \t x(t)
\end{pmatrix} + 
\begin{pmatrix}
B M \\ 0
\end{pmatrix}r(t), \; t\geq 0
\end{split}
\end{align}
is asymptotically stable. With straightforward calculation, the steady state results in  
\begin{align}
\lim_{t \to \infty}\begin{pmatrix}
x(t) \\ \t x(t)
\end{pmatrix} = \begin{pmatrix}
(I - A + BF)^{-1 }BM \\ 0
\end{pmatrix}r_0.
\end{align}

Choose $M$ as a right inverse of the matrix 
\begin{align}
D + (C - D F) (I - A + B F)^{-1} B,
\end{align}
then \begin{align}
\lim_{t \to \infty} y(t) = 
\begin{pmatrix}
C - DF & DF
\end{pmatrix}
\begin{pmatrix}
(I - A + BF)BM \\ 0
\end{pmatrix}
r_0 + D M r_0 = r_0.
\end{align}
This controller design can also be used for the piecewise constant signals $r(\cdot)$, if the tracking signal does not change too fast. 
