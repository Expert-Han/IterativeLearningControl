\chapter{Basics} 
\label{ch:Basics}

To understand the following Iterative Learning Control (ILC) algorithms, we need to make a departure to basic definitions we will use. 
We consider the system \eqref{eq:Intro:GP}. Here $A \in \mathbb{R}^{n\times n}$, $B \in \mathbb{R}^{n \times l}$, $C \in \R^{m \times n}$, and $D \in \R^{m\times l}$ are real matrices, $r(t) \in \R^{m}$ is a reference signal at time $t$. For notation simplification, we write $(A, B,C,D)$ and mean it to be the discrete-time control system \eqref{eq:Intro:GP}.



%We consider a  discrete time iteration
%\begin{align}
%\label{eq:GP}
%\begin{split}
%&\begin{array}{c c c c c}
%x(t+1) &= &A x(t)& + &B u(t)  \\
%y ( t) &= &C x(t)&  + &D u(t),\\ 
%\end{array}\\
%&\; \;\;x(0) =x_0 , \; \;  t \geq 0,
%\end{split}
%\end{align}
% with error 
%\begin{align}
%\label{eq:error}
%e(t) =r(t) - y(t)
%\end{align}
%at time $t  = 0, 1, 2, \dots$.





We aim to find a ''good'' input signal $u(t)$, such that the reference $r(t)$ is tracked possibly well for all $t \geq 0$. With other words, it means, that the error norm $||e(\cdot)||$ must stay small in some  $||\cdot||$, e.g. the $L_2$-norm.
To find it we usually design a stabilizing controller 
 -- such that our system state goes not to infinity over time $t$. 
To design it, we must first clearly define what stability means. Since let us first formulate the common definitions and entertain ideas of a stabilizing controller design. 

\section{Stability and stabilizability}


The stability definition is usually given asymptotically. That means, we assume $N = \infty$. Only for definitions in this section, we make this assumption. We will see, that it quite make sense also for finite time horizon problems.  

\begin{defi}
	A discrete time dynamical system
	\begin{align}
	\label{eq:x=Ax}
	x(t+1) = A x(t)
	\end{align}
	for $t \geq 0$ 
	is said to be asymptotically stable, if for all initial conditions $x(0) \in \R^n$
	\begin{align}
	\lim_{t \to \infty} x(t) = 0
	\end{align}	
    is satisfied. 
	It is said to be stable, if 
	\begin{align}
	\limsup_{t \to \infty} ||x(t)|| < \infty
	\end{align}
	for all	 initial conditions $x(0) \in \R^n$.
	We call the matrix $A$ (asymptotically) stable, if the dynamical system \eqref{eq:x=Ax} is (asymptotically) stable.
\end{defi}


In the same way we want to define (asymptotic) stabilizability and detectability. 
\begin{defi}
A a discrete time system $(A, B, C, D)$ or the pair $(A, B)$ is (asymptotically) stabilizable, if there exists a matrix $F$, such that $A - BF$ is (asymptotically) stable.
The system or the pair $(A,C)$ is detectable, if $(A^T, C^T)$ is assymptotically stabilizable. 
\end{defi}

\section{Supervector description} 

The supervectors are our most useful tool in this thesis. By ''stocking'' the signals together, we get a compact system representation in linear form. More precise, let us define what a supervector means.  


\begin{defi}
	Let $\{s(0), s(1), s(2), \dots s(N)\} \subset \R^{d}$ be a finite sequence. Then the supervector corresponding to this sequence is denoted by $s$ and is defined as 
	\begin{align}
	s: = \begin{pmatrix}
	s(0) \\ s(1) \\ s(2) \\ \vdots \\ s(N)
	\end{pmatrix}.
	\end{align}
\end{defi}

In this way we define the supervectors $u \in \R^{l(N+1)} $ and $e$, $y$, $r \in \R^{m(N+1)}$.  

For system \eqref{eq:Intro:GP} the relation between $u$ and $y$, and the error $e$ can be written as
\begin{align}
\label{eq:Gu + d}
y &= Gu + d, \\
e &= r - y.
\end{align}
The \textit{supermatrix} $G$ represents the state-space model and is given via  
\begin{align}
\label{eq:Gmatrix}
\begin{split}
G &= G(A,B,C,D) = \\
&=  \begin{pmatrix}
D & 0 & \cdots & 0 & 0 & 0 \\
CB & D & \cdots & 0 & 0 & 0\\
CAB & CB & \cdots & 0 & 0 & 0\\
\vdots & \vdots & \ddots & \vdots  & \vdots & \vdots \\
CA^{N-2} B & CA^{N-3} B &\dots &CB & D& 0\\
CA^{N-1} B & CA^{N-2} B &\dots &CAB & CB& D\\
\end{pmatrix} \in \R^{m(N+1)\times l(N+1)}.
\end{split}
\end{align}
The vector $d$ depends on the initial condition $x_0$:
\begin{align}
d = d(C,A,x_0) = \begin{pmatrix}
C x_0 \\ CA x_0 \\ CA^2 x_0 \\ \vdots \\ CA^Nx_0
\end{pmatrix} \in \R^{m(N+1)}.
\end{align}

The stability requirement for $A$ is highlighted here. In opposite to vast values for unstable matrices, we get very small terms if $N \gg 1$. Intuitive, this terms can be neglected for all $p > p^\star$ for some $1<p^\star<N$. This is usable since we can apply the sparse matrices. In the Chapter \ref{ch:Allpication} we will derive an estimation in case of small terms neglecting. 


\section{Stabilizing Controller}
\label{ch:stabilizingController}

There are several ways to construct a stabilizing controller for the system $(A, B, C, D)$. It could be an LQR controller, $\c H_{\infty}$ design, pole placement or other methods.



At first glance, the stability concept seems to be not necessary for $N < \infty$ . Still, in this thesis, it is the requirement we presuppose on considered system. The reason is that also the discrete system over finite horizon can produce vast signals for large $N$, if the system is not stable. Especially, it means, that $A$ has at least one eigenvalue larger that one, which implies very large norm of the matrices $A^t$ for $t \gg 1$. This makes difficult the numerical calculations for matrix $G$, as well as the for the solution of \eqref{eq:Intro:GP}. 

 A good tracking is mostly the main goal in controller design. However, in our case we are more interested in better stabilizing properties, as in a good performance. The algorithms we will consider guarantee the convergence to a good input, but to apply this algorithms we also need some numerically stability. 

The placement method is described in \cite{LKT}. More about $\c H_{\infty}$ design for discrete systems one finds in \cite{discrHinf} (TODO: change?). 
We present here only the controller based on Separation Principle, as a most simple solution. Nevertheless, one should keep in mind, Separation Principle might be not the best solution for preparation to ILC algorithms. In the Chapter \ref{ch:Allpication} we will consider an example where it is the case. 

\section{Separation Principle} 

We can find a stabilizing controller for \eqref{eq:Intro:GP} using feedback control.
Let us first consider the case $y(\cdot) = x(\cdot)$.

Then the system \eqref{eq:Intro:GP} becomes stable, if we choose $u(t) = -Fx(t)$, $t \geq 0$, with some matrix $F$, such that $(A - BF)$ is stable.

Clearly, if the system is (asymptotically) stabilizable, we can find such matrix $F$. 

But what is a ''good'' choice for $F$? One option is the so-called Linear-Quadratic-Regulator (LQR), which minimizes the cost function 
\begin{align}
\label{eq:costFcn}
V(u(\cdot)) = \sum_{t = 0}^\infty \left( (x(t))^T Q (x(t)) + u(t)^T R u(t)\right),
\end{align}
overall stabilizing piecewise constant input signals $u(\cdot) \in \R^m$, and with $x(\cdot)$ satisfying \eqref{eq:GP} (for $C = I$ and $D = 0$). 
$Q \succ 0$ and $R \succ 0$ are here weighing matrices, which allow us to decide how ''important'' the elements of the in- and output signals are.  
Using them, we can make one input signal impact the system more than another or drive one of the output signals faster. 

Choosing the weighting matrices always depends on the system we work with and allows us to affect closed-loop behavior.   

The optimal $u(\cdot)$ for minimizing of the cost function \eqref{eq:costFcn} is given via $u(t) = F x(t)$ with
\begin{align}
\label{eq:Basics:F}
F = (R + B^T P B)^{-1}B^TPA.
\end{align}
The matrix $P$ is a unique symmetric positive definite matrix, the stabilizing solution of the discrete time algebraic Riccati equation
\begin{align}
 A^TA - A^T P B (R + B^T P B)^{-1} B^T P A + Q - P = 0 \text{ \cite{DAREandLMI} }.
\end{align}
Stabilizing solution means, that from \eqref{eq:Basics:F} resulting matrix $(A - BF)$ is stable, and hence this solution stabilizes our system. 


For the case $y(\cdot) \neq x(\cdot)$, we can additionally construct an observer to approximate the signal $x(\cdot)$. The  controller we get is said to be based on \textit{separation principle}.
It requires the pair $(A,C)$ to be detectable. So, we can find a matrix $J$, for which $A - JC$ is asymptotically stable.

We set 
\begin{align}
u(\cdot)= -F \hat{x}(\cdot), \text{ with } \hat{x}(\cdot) \text{ given via dynamical system }
\end{align}
\begin{align}
\hat{x}(t+1) &= A\hat{x}(t) + B u(t) + J (y - \hat{y}(t)), \\
\hat{y}(t) & = C\hat{x}(t) + D u(t), \\
\hat{x}(0)& = x_0, \; t \geq 0. 
\end{align}
With this observer system the estimation error can be calculated as \begin{align}
\tilde{x}(t+1) = x(t+1) - \hat{x}(t+1) = (A - JC) \tilde{x}(t), \, t \geq 0,
\end{align} and hence $\hat{x} (\cdot)$ converges to $x(\cdot)$ at least asymptotically. 

We elect
\begin{align}
u(\cdot) = -F\hat{x}(\cdot) + Mr(\cdot), 
\end{align}
where $M$ is a right inverse of the matrix 
\begin{align}
D + (C - D F) (I - A + B F)^{-1} B.
\end{align}

This choice of input signal 
solves tracking issue for constant $r(\cdot)$. It still can be used for piecewise constant $r(\cdot)$, if the signal does not change too fast.
