\chapter{Introduction}

\section{Motivation} 

It is well known that repetition is the mother of learning. A student learning a piano piece repeats it till he or she can play it well, and, possibly, without errors. 
A gymnastic tries to make a perfect move by exercising it dozens or hundreds of times. 
In both cases, the correct motion is learned and becomes ingrained into muscle memory. The converged muscle motion profile can bee seen as an open-loop control generated through repetition and learning \cite{Bristov06}. This type of learned open-loop control strategy is the essence of Iterative Learning Control (ILC). 

Nowadays, more and more tasks are carried out by industrial machines or robots. The machines can achieve better precision, and can perform dangerous or heavy work. It is often a cheap and effective solution for big industrial companies. ILC provides a great tool for performance improving, if a task needs to be done frequently. 

For example, imagine a robot arm which needs to take the same path, again and again, with high accuracy. There possibly exists a controller, which might run the robot arm along this route. However, to achieve good precision, a simple controller might not be enough, and more complicated techniques must be applied to impact the result. 

The other possibility is to design a simpler controller, and try to ''learn'' something from the resulting input and output signals. The input signal can than be adjusted to achieve better performance. By doing so run after run there is possible to achieve an almost perfect result with less effort, if the signal is adapted with a proper algorithm. 

In this thesis some of such algorithms are presented for the discrete finite time dynamical systems. Their advantages and disadvantages are discussed, the robust stability property is considered. The examples, made using computer simulations, illustrate the practical use of the algorithms. For the application purposes there are also some difficulties discussed and remedies are proposed. 

\section{Problem Statement}


There are many different ILC algorithms. One can find a good overview in \cite{Bristov06}.
The focus of this work is studying the so-called unit memory algorithms on the example of discrete-time dynamical systems over a finite time horizon. 
%We also aim to prove the robustness property for these algorithms despite the parameter uncertainty. Besides, we want to apply the algorithms we provide on discrete- and continuous-time systems. Especially, we face the issues that occur due to system discretization, the amount of data and numerical instability. 


The unit memory algorithms are the ones, which can ''remember'' the last pass. Mathematically speaking, if $u_k$ is the input signal and $e_k$ is the tracking error at trial $k$, then
\begin{align*}
u_{k+1} = f(e_k, e_{k+1}, u_k),
\end{align*}
where $f$ is some function independent on $k$ \cite{ILC}. 

The $l$-input $m$-output discrete time systems can be written as 
\begin{align*}
%\label{eq:Intro:GP}
\begin{split}
&\begin{array}{c c c c c}
x(t+1) &= &A x(t)& + &B u(t)  \\
y ( t) &= &C x(t)&  + &D u(t),\\ 
x(0)& = &x_0, & &
\end{array}\\
\end{split}
\end{align*}
over a time horizon $t = 0, 1, 2, \dots, N$. $A \in \R^{n \times n}$, $B\in \R^{l \times n}$, $C \in \R^{m \times n}$, and $D\in \R^{m \times l}$ denote  real matrices.
We are interested in the minimizing of the error between output $y(\cdot)$ and the tracking signal $r(\cdot)$
\begin{align*}
%\label{eq:Intro:error}
e(t) = r(t) - y(t), \; t  = 0, 1, 2, \dots, N. 
\end{align*}

An uncommon contemplation in this work is the final time horizon. 
Together with discreteness of the system it invites us to rewrite the system \eqref{eq:Intro:GP} in a more compact form. We ''stock'' the sequences 
\begin{align*}\{u(0), u(1), u(2), \dots, u(N)\} \text{ and } \{y(0), y(1), y(2), \dots, y(N)\} \end{align*}
as
\begin{align*}
u = \begin{pmatrix}
u(0) \\ u(1) \\ \vdots \\ u(N)
\end{pmatrix} \text{ and }
y = \begin{pmatrix}
y(0) \\ y(1) \\ \vdots \\ y(N)
\end{pmatrix}. 
\end{align*}
The resulting vectors $u$ and $y$ are called supervectors. 

Then the system \eqref{eq:Intro:GP} can be expressed as 
\begin{align*}
y = G u + d, 
\end{align*}
where 
\begin{align*}
\begin{split}
G &= G(A,B,C,D) = \\
&=  \begin{pmatrix}
D & 0 & \cdots & 0 & 0 & 0 \\
CB & D & \cdots & 0 & 0 & 0\\
CAB & CB & \cdots & 0 & 0 & 0\\
\vdots & \vdots & \ddots & \vdots  & \vdots & \vdots \\
CA^{N-2} B & CA^{N-3} B &\dots &CB & D& 0\\
CA^{N-1} B & CA^{N-2} B &\dots &CAB & CB& D\\
\end{pmatrix} \in \R^{m(N+1)\times l(N+1)}.
\end{split}
\end{align*}
and 
\begin{align*}
d = d(C,A,x_0) = \begin{pmatrix}
C x_0 \\ CA x_0 \\ CA^2 x_0 \\ \vdots \\ CA^Nx_0
\end{pmatrix} \in \R^{m(N+1)}.
\end{align*}
With other words, we put all the information about the system at the times $t = 0, 1,  \dots, N$ in one linear equation. This form inspires some of ILC algorithms, for example the Inverse Model Algorithm (Chapter \ref{ch:ILCAlg}), which uses the inverse of the matrix $G$. 

To make the notation less confusing, we denote with $u(t)$ the value of signal $u(\cdot)$ at time $t$, and with $u$ the corresponding supervector form. With $u_k$ is denoted the supervector in the $k$-th trial of algorithm run.

Five different algorithms are illustrated in this work. Two of them are derived based on inverse model consideration, two are inspired by steepest descent, and one is based on feedback design. The algorithms in this thesis are taken from \cite{ILC}. However, some of them were modified in a more compact way.

Furthermore, we consider the robustness property of Unit Memory Algorithms despite the parametric uncertainty. Using Lyapunov techniques and 
Full-Block S-Procedure we derive a method, which allows us to check whether the given algorithm stays stable if the parameters of the system are uncertain. 

Moreover, we discuss the issues appearing by the application of the algorithms. With the supervector description, the ILC algorithms need a lot of computational memory and lead to significant numerical errors. We need to modify the algorithms in a way, so that we can apply them to the real problems.

\section{Structure}

This work consists of 6 chapters. In the first chapter we formulate the problem.
In Chapter \ref{ch:Basics}, we recap the crucial basics for understanding the considered algorithms. In Chapter \ref{ch:ILCAlg}  we introduce the supervector notation and inspired by it, derive the ILC algorithms. In chapter \ref{ch:Robustness} we succeed the requirements, under which the algorithms stay robust despite the parametric uncertainty. Finally, in chapter \ref{ch:Allpication} we want to apply ILC algorithms to a real dynamical system. We face the issues the real problems yield, and suggest the remedies. The summary concludes this thesis, and further work is suggested. 










 



 


 


 





 
