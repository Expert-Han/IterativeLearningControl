\chapter{Basics on the discrete time systems}

The systems we are interested in are discrete time linear systems, over a finite time interval. Such systems can be described as 
\begin{align}
\label{eq: sys4LQR}
x(t+1) &= A x(t) + B u(t),
\end{align}
for $t = 0, 1, \dots, N$, $N \in \N$, $x(0) = x_0$, if we first assume the output $y(t) = x(t)$ for all $t$. 

Since there are some differences between continuous and discrete systems, let us first get to know some theory on them. In particular, we are interested in a stabilizing controller for \eqref{eq: sys4LQR}. To be able to find such a controller, we need to define what we understand under stability and how we can find out, whether a given system is stable. 

For begin, let us consider the systems over an infinite horizon: $t \geq 0$.
\begin{defi}
	A discrete time dynamical system
	\begin{align}
	x(t+1) = A x(t)
	\end{align}
	for $t \geq 0$ 
	is said to be stable, if all solutions satisfy 
	\begin{align}
	\lim_{t \to \infty} x(t) = 0.
	\end{align}	
\end{defi}
\begin{theo}
	A discrete time dynamical system 
	\begin{align}
	x(t+1) = A x(t)
	\end{align}
	for $t \geq 0$ 
	is stable, if and only if each eigenvalue of the matrix $A$ lies within the unit circle: $\lambda \in \{x \in \C: \; |x|<1\}.$
\end{theo}
\begin{proof}
	content...
\end{proof}

If we assume feedback control, then we are looking for a matrix $F$, such that $(A - BF)$ has its eigenvalues within the unit circle. Then the system \eqref{eq: sys4LQR} becomes stable, if we choose $u(t) = -Fx(t)$. 

If the system is controllable (that is the Kalman-matrix $\begin{bmatrix}
B & AB & A^2B & \cdots & A^{n-1}B
\end{bmatrix}$ has full row rank) or stabilizable (that means all uncontrollable modes lie within the unit circle), then we can always find such a matrix $F$ (\cite{LKT}). 


But what is a ''good'' choice for $F$? One selection is the so-called Linear-Quadratic-Regulator (LQR), which minimizes the cost function 
\begin{align}
\label{eq: costFcn}
V = \sum_{t = 0}^N x(t)^T Q x(t) + \sum_{t = 0}^{N-1} u(t)^T R u(t),
\end{align}
over all  input signals $u(t) \in \R^m$, $t = 0,1,2, \dots, N-1$. 
$Q \succeq 0$ and $R \succ 0$ are here the weighting matrices. 

The solution of this problem is given by choosing
\begin{align}
u(t) = -F(t) x(t),
\end{align}
where 
\begin{align}
F(t) = (R +B^TP(t+1)B)^{-1}(B^TP(t+1)A).
\end{align}
$P(t)$ is found iteratively by solving dynamic Riccati equation: 
\begin{align}
\begin{split}
P(t-1) &= A^TP(t) A - (A^T P(t) B)(R + B^TP(t)B)^{-1}(B^T P(t)A) + Q,\\
P(N) &= Q.
\end{split}
\end{align}
{\color{red} Quelle? Wiki sagt Chow, Gregory C. (1986). Analysis and Control of Dynamic Economic Systems. Krieger Publ. Co.} 

\section{Observer-based Controller}
LQR is a good choice for full-information control -- i.e. $y(t) = x(t)$. 

Now let us consider a system 
\begin{align}
x(t+1) &= A x(t) + B u(t)\\
y(t)   &= C x(t) + B u(t),
\end{align}
$t \geq 0$. 
%TODO: finite or infinite time horizon? 
Then the observer-based controller is given via 
$u(t) = r(t) - v(t)$, where $v(\cdot)$ the output of the dynamic system
\begin{align}
x_K(t+1) & = (A - LC)x_K(t) - (B - LD) u(t) + Ly(t)\\
v(t) & = Fx_K(t).
\end{align}
$t \geq 0$. 
































 

